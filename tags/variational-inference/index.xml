<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Variational-inference on Yida Wang</title>
    <link>https://wangyida.github.io/tags/variational-inference/</link>
    <description>Recent content in Variational-inference on Yida Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Yida Wang</copyright>
    <lastBuildDate>Fri, 01 Jun 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://wangyida.github.io/tags/variational-inference/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Generative Model with Coordinate Metric Learning for Object Recognition Based on 3D Models</title>
      <link>https://wangyida.github.io/publication/tip2018_wang/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://wangyida.github.io/publication/tip2018_wang/</guid>
      <description>input target manifold           Method pipeline. Image analysis for average and standard deviation for data released together with our paper. Examples for triplet set used in our metric learning. 4 nearest neighboour retrieval results based on simple models. Examples for real world tasks Depth prediction Example for depth prediction based on RGB images. Scene understanding Examples for videos collected by Bleenco.</description>
    </item>
    
    <item>
      <title>Variational Inference</title>
      <link>https://wangyida.github.io/project/variational-inference/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://wangyida.github.io/project/variational-inference/</guid>
      <description>Variational Bayesian methods are a family of techniques for approximating intractable integrals arising in Bayesian inference and machine learning. They are typically used in complex statistical models consisting of observed variables (usually termed &amp;ldquo;data&amp;rdquo;) as well as unknown parameters and latent variables, with various sorts of relationships among the three types of random variables, as might be described by a graphical model. As is typical in Bayesian inference, the parameters and latent variables are grouped together as &amp;ldquo;unobserved variables&amp;rdquo;.</description>
    </item>
    
  </channel>
</rss>