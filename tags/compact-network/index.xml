<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Compact-network on Yida Wang</title>
    <link>https://wangyida.github.io/tags/compact-network/</link>
    <description>Recent content in Compact-network on Yida Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Yida Wang</copyright>
    <lastBuildDate>Sun, 12 Mar 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://wangyida.github.io/tags/compact-network/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ZigzagNet: Efficient Deep Learning for Real Object Recognition Based on 3D Models</title>
      <link>https://wangyida.github.io/publication/accv16_wang/</link>
      <pubDate>Sun, 12 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://wangyida.github.io/publication/accv16_wang/</guid>
      <description>More detail can easily be written here using Markdown and $\rm \LaTeX$ math code.</description>
    </item>
    
    <item>
      <title>Compact Network</title>
      <link>https://wangyida.github.io/project/compact-network/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://wangyida.github.io/project/compact-network/</guid>
      <description>Zigzagnet Effective utilization on texture-less 3D models for deep learning is significant to recognition on real photos. We eliminate the reliance on massive real training data by modifying convolutional neural network in 3 aspects: synthetic data rendering for training data generation in large quantities, multi-triplet cost function modification for multi-task learning and compact micro architecture design for producing tiny parametric model while overcoming over-fit problem in texture-less models. Network is initiated with multi-triplet cost function establishing sphere-like distribution of descriptors in each category which is helpful for recognition on regular photos according to pose, lighting condition, background and category information of rendered images.</description>
    </item>
    
  </channel>
</rss>