<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications with demos on Yida Wang</title>
    <link>https://example.com/posts/</link>
    <description>Recent content in Publications with demos on Yida Wang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Nov 2019 10:15:01 +0200</lastBuildDate>
    
      <atom:link href="https://example.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
      <item>
        <title>ForkNet - Multi-Branch Volumetric Semantic Completion From a Single Depth Image</title>
        <link>https://example.com/2019/11/01/youtube/</link>
        <pubDate>Fri, 01 Nov 2019 10:15:01 +0200</pubDate>
        <guid>https://example.com/2019/11/01/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@inproceedings{wang2019forknet, title={ForkNet: Multi-branch Volumetric Semantic Completion from a Single Depth Image}, author={Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico}, booktitle={Proceedings of the IEEE International Conference on Computer Vision}, pages={8608--8617}, year={2019} } Abstrarct We propose a novel model for 3D semantic completion from a single depth image, based on a single encoder and three separate generators used to reconstruct different geometric and semantic representations of the original and completed scene, all sharing the same latent space.</description>
      </item>
    
      <item>
        <title>Variational Object-aware 3D Hand Pose from a Single RGB Image</title>
        <link>https://example.com/2019/06/01/youtube/</link>
        <pubDate>Sat, 01 Jun 2019 10:15:01 +0200</pubDate>
        <guid>https://example.com/2019/06/01/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@article{gao2019variational, title={Variational Object-Aware 3-D Hand Pose From a Single RGB Image}, author={Gao, Yafei and Wang, Yida and Falco, Pietro and Navab, Nassir and Tombari, Federico}, journal={IEEE Robotics and Automation Letters}, volume={4}, number={4}, pages={4239--4246}, year={2019}, publisher={IEEE} } Abstrarct We propose an approach to estimate the 3D pose of a human hand while grasping objects from a single RGB image.</description>
      </item>
    
      <item>
        <title>Adversarial Semantic Scene Completion from a Single Depth Image</title>
        <link>https://example.com/2018/10/09/youtube/</link>
        <pubDate>Tue, 09 Oct 2018 10:15:01 +0200</pubDate>
        <guid>https://example.com/2018/10/09/youtube/</guid>
        <description>If you find this work useful in yourr research, please cite:
@inproceedings{wang2018adversarial, title={Adversarial semantic scene completion from a single depth image}, author={Wang, Yida and Tan, David Joseph and Navab, Nassir and Tombari, Federico}, booktitle={2018 International Conference on 3D Vision (3DV)}, pages={426--434}, year={2018}, organization={IEEE} } Abstrarct We propose a method to reconstruct, complete and semantically label a 3D scene from a single input depth image. We improve the accuracy of the regressed semantic 3D maps by a novel architecture based on adversarial learning.</description>
      </item>
    
  </channel>
</rss>
