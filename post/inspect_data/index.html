<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.45" />
  <meta name="author" content="Yida Wang">

  
  
  
  
    
      
    
  
  <meta name="description" content="Mask R-CNN - 检查训练数据 检查并可视化数据加载和预处理代码。
import os import sys import itertools import math import logging import json import re import random from collections import OrderedDict import numpy as np import matplotlib import matplotlib.pyplot as plt import matplotlib.patches as patches import matplotlib.lines as lines from matplotlib.patches import Polygon import utils import visualize from visualize import display_images import model as modellib from model import log %matplotlib inline ROOT_DIR = os.getcwd()  Using TensorFlow backend.">

  
  <link rel="alternate" hreflang="en-us" href="https://wangyida.github.io/post/inspect_data/">

  


  

  
  
  <meta name="theme-color" content="#3f51b5">
  
  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">
  
  
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Montserrat:400,700%7cRoboto:400,400italic,700%7cRoboto&#43;Mono">
  
  <link rel="stylesheet" href="/styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-108746836-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://wangyida.github.io/post/inspect_data/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Yida Wang">
  <meta property="og:url" content="https://wangyida.github.io/post/inspect_data/">
  <meta property="og:title" content=" | Yida Wang">
  <meta property="og:description" content="Mask R-CNN - 检查训练数据 检查并可视化数据加载和预处理代码。
import os import sys import itertools import math import logging import json import re import random from collections import OrderedDict import numpy as np import matplotlib import matplotlib.pyplot as plt import matplotlib.patches as patches import matplotlib.lines as lines from matplotlib.patches import Polygon import utils import visualize from visualize import display_images import model as modellib from model import log %matplotlib inline ROOT_DIR = os.getcwd()  Using TensorFlow backend.">
  <meta property="og:locale" content="en-us">
  
  
  
  

  

  

  <title> | Yida Wang</title>

</head>
<body id="top" data-spy="scroll" data-target="#toc" data-offset="71" >

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
      <a class="navbar-brand" href="/">Yida Wang</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      
      <ul class="nav navbar-nav navbar-right">
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        
        
        
        
        
          
        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        
      

      
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name"></h1>

    

<div class="article-metadata">

  

  <span class="article-date">
    
    <meta content="" itemprop="datePublished">
    <time datetime="" itemprop="dateModified">
      0001-01-01
    </time>
  </span>
  <span itemscope itemprop="author publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Yida Wang">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    9 min read
  </span>
  

  
  

  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=&amp;url=https%3a%2f%2fwangyida.github.io%2fpost%2finspect_data%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fwangyida.github.io%2fpost%2finspect_data%2f"
         target="_blank" rel="noopener">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fwangyida.github.io%2fpost%2finspect_data%2f&amp;title="
         target="_blank" rel="noopener">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fwangyida.github.io%2fpost%2finspect_data%2f&amp;title="
         target="_blank" rel="noopener">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=&amp;body=https%3a%2f%2fwangyida.github.io%2fpost%2finspect_data%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>


    <div class="article-style" itemprop="articleBody">
      

<h1 id="mask-r-cnn-检查训练数据">Mask R-CNN  - 检查训练数据</h1>

<p>检查并可视化数据加载和预处理代码。</p>

<pre><code class="language-python">import os
import sys
import itertools
import math
import logging
import json
import re
import random
from collections import OrderedDict
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib.lines as lines
from matplotlib.patches import Polygon

import utils
import visualize
from visualize import display_images
import model as modellib
from model import log

%matplotlib inline 

ROOT_DIR = os.getcwd()
</code></pre>

<pre><code>Using TensorFlow backend.
</code></pre>

<h2 id="配置">配置</h2>

<p>运行下面的代码块之一来导入和加载要使用的配置。</p>

<pre><code class="language-python"># Run one of the code blocks

# Shapes toy dataset
# import shapes
# config = shapes.ShapesConfig()

# MS COCO Dataset
import coco
config = coco.CocoConfig()
COCO_DIR = &quot;path to COCO dataset&quot;  # TODO: enter value here
</code></pre>

<h2 id="数据集">数据集</h2>

<pre><code class="language-python"># 加载数据集
if config.NAME == 'shapes':
    dataset = shapes.ShapesDataset()
    dataset.load_shapes(500, config.IMAGE_SHAPE[0], config.IMAGE_SHAPE[1])
elif config.NAME == &quot;coco&quot;:
    dataset = coco.CocoDataset()
    dataset.load_coco(COCO_DIR, &quot;train&quot;)

# 在使用数据集之前必须调用
dataset.prepare()

print(&quot;Image Count: {}&quot;.format(len(dataset.image_ids)))
print(&quot;Class Count: {}&quot;.format(dataset.num_classes))
for i, info in enumerate(dataset.class_info):
    print(&quot;{:3}. {:50}&quot;.format(i, info['name']))
</code></pre>

<pre><code>loading annotations into memory...
Done (t=11.93s)
creating index...
index created!
Image Count: 82081
Class Count: 81
  0. BG                                                
  1. person                                            
  2. bicycle                                           
  3. car                                               
  4. motorcycle                                        
  5. airplane                                          
  6. bus                                               
  7. train                                             
  8. truck                                             
  9. boat                                              
 10. traffic light                                     
 11. fire hydrant                                      
 12. stop sign                                         
 13. parking meter                                     
 14. bench                                             
 15. bird                                              
 16. cat                                               
 17. dog                                               
 18. horse                                             
 19. sheep                                             
 20. cow                                               
 21. elephant                                          
 22. bear                                              
 23. zebra                                             
 24. giraffe                                           
 25. backpack                                          
 26. umbrella                                          
 27. handbag                                           
 28. tie                                               
 29. suitcase                                          
 30. frisbee                                           
 31. skis                                              
 32. snowboard                                         
 33. sports ball                                       
 34. kite                                              
 35. baseball bat                                      
 36. baseball glove                                    
 37. skateboard                                        
 38. surfboard                                         
 39. tennis racket                                     
 40. bottle                                            
 41. wine glass                                        
 42. cup                                               
 43. fork                                              
 44. knife                                             
 45. spoon                                             
 46. bowl                                              
 47. banana                                            
 48. apple                                             
 49. sandwich                                          
 50. orange                                            
 51. broccoli                                          
 52. carrot                                            
 53. hot dog                                           
 54. pizza                                             
 55. donut                                             
 56. cake                                              
 57. chair                                             
 58. couch                                             
 59. potted plant                                      
 60. bed                                               
 61. dining table                                      
 62. toilet                                            
 63. tv                                                
 64. laptop                                            
 65. mouse                                             
 66. remote                                            
 67. keyboard                                          
 68. cell phone                                        
 69. microwave                                         
 70. oven                                              
 71. toaster                                           
 72. sink                                              
 73. refrigerator                                      
 74. book                                              
 75. clock                                             
 76. vase                                              
 77. scissors                                          
 78. teddy bear                                        
 79. hair drier                                        
 80. toothbrush                                        
</code></pre>

<h2 id="显示样本">显示样本</h2>

<p>加载并显示原始图像和掩模图像。</p>

<pre><code class="language-python"># Load and display random samples
image_ids = np.random.choice(dataset.image_ids, 4)
for image_id in image_ids:
    image = dataset.load_image(image_id)
    mask, class_ids = dataset.load_mask(image_id)
    visualize.display_top_masks(image, mask, class_ids, dataset.class_names)
</code></pre>

<p><img src="output_7_0.png" alt="png" /></p>

<p><img src="output_7_1.png" alt="png" /></p>

<p><img src="output_7_2.png" alt="png" /></p>

<p><img src="output_7_3.png" alt="png" /></p>

<h2 id="边界框">边界框</h2>

<p>我们不是使用源数据集提供的边界框坐标，而是使用掩码来计算边界框。这使得我们无论源数据集如何都能够一致地处理边界框，并且还可以更轻松地调整大小，旋转或裁剪图像，因为我们只是从更新掩码生成边界框，而不是计算每种图像类型的边界框转换转型。</p>

<pre><code class="language-python"># Load random image and mask.
image_id = random.choice(dataset.image_ids)
image = dataset.load_image(image_id)
mask, class_ids = dataset.load_mask(image_id)
# Compute Bounding box
bbox = utils.extract_bboxes(mask)

# Display image and additional stats
print(&quot;image_id &quot;, image_id, dataset.image_reference(image_id))
log(&quot;image&quot;, image)
log(&quot;mask&quot;, mask)
log(&quot;class_ids&quot;, class_ids)
log(&quot;bbox&quot;, bbox)
# Display image and instances
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
</code></pre>

<pre><code>image_id  74886 http://cocodataset.org/#explore?id=118535
image                    shape: (375, 500, 3)         min:    0.00000  max:  255.00000
mask                     shape: (375, 500, 5)         min:    0.00000  max:    1.00000
class_ids                shape: (5,)                  min:    1.00000  max:   35.00000
bbox                     shape: (5, 4)                min:    1.00000  max:  329.00000
</code></pre>

<p><img src="output_9_1.png" alt="png" /></p>

<h2 id="调整图像大小">调整图像大小</h2>

<p>为了支持每批次的多个图像，图像被调整为一个尺寸（1024x1024）。纵横比保存，但。如果图像不是正方形，则会在顶部/底部或右侧/左侧添加零填充。</p>

<pre><code class="language-python"># Load random image and mask.
image_id = np.random.choice(dataset.image_ids, 1)[0]
image = dataset.load_image(image_id)
mask, class_ids = dataset.load_mask(image_id)
original_shape = image.shape
# Resize
image, window, scale, padding = utils.resize_image(
    image, 
    min_dim=config.IMAGE_MIN_DIM, 
    max_dim=config.IMAGE_MAX_DIM,
    padding=config.IMAGE_PADDING)
mask = utils.resize_mask(mask, scale, padding)
# Compute Bounding box
bbox = utils.extract_bboxes(mask)

# Display image and additional stats
print(&quot;image_id: &quot;, image_id, dataset.image_reference(image_id))
print(&quot;Original shape: &quot;, original_shape)
log(&quot;image&quot;, image)
log(&quot;mask&quot;, mask)
log(&quot;class_ids&quot;, class_ids)
log(&quot;bbox&quot;, bbox)
# Display image and instances
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
</code></pre>

<pre><code>/usr/local/lib/python3.5/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
  &quot;the returned array has changed.&quot;, UserWarning)


image_id:  6480 http://cocodataset.org/#explore?id=402563
Original shape:  (476, 640, 3)
image                    shape: (1024, 1024, 3)       min:    0.00000  max:  255.00000
mask                     shape: (1024, 1024, 32)      min:    0.00000  max:    1.00000
class_ids                shape: (32,)                 min:    1.00000  max:   77.00000
bbox                     shape: (32, 4)               min:    1.00000  max:  991.00000
</code></pre>

<p><img src="output_11_2.png" alt="png" /></p>

<h2 id="迷你掩模图像">迷你掩模图像</h2>

<p>使用高分辨率图像进行训练时，实例二进制蒙版可能会变大。例如，如果使用1024x1024映像训练，那么单个实例的掩码需要1MB的内存（Numpy使用字节作为布尔值）。如果一个图像有100个实例，那么只有100MB的掩码。</p>

<p>为了提高训练速度，我们通过以下方式优化口罩：
*我们存储对象边界框内的蒙版像素，而不是完整图像的蒙版。大多数物体与图像大小相比都很小，所以我们通过不在物体周围存储大量零来节省空间。
*我们将面罩调整为较小的尺寸（例如56x56）。对于大于所选大小的对象，我们会失去一点准确性。但是大多数对象注释的开头并不是很精确，所以对于大多数实际用途来说，这种损失是可以忽略的。可以在配置类中设置mini_mask的大小。</p>

<p>为了可视化掩码大小调整的效果，并验证代码的正确性，我们可以看到一些示例。</p>

<pre><code class="language-python">image_id = np.random.choice(dataset.image_ids, 1)[0]
image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(
    dataset, config, image_id, use_mini_mask=False)

log(&quot;image&quot;, image)
log(&quot;image_meta&quot;, image_meta)
log(&quot;class_ids&quot;, class_ids)
log(&quot;bbox&quot;, bbox)
log(&quot;mask&quot;, mask)

display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 7))])
</code></pre>

<pre><code>image                    shape: (1024, 1024, 3)       min:    0.00000  max:  255.00000
image_meta               shape: (89,)                 min:    0.00000  max: 23221.00000
bbox                     shape: (1, 5)                min:   62.00000  max:  578.00000
mask                     shape: (1024, 1024, 1)       min:    0.00000  max:    1.00000
</code></pre>

<p><img src="output_13_1.png" alt="png" /></p>

<pre><code class="language-python">visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
</code></pre>

<p><img src="output_14_0.png" alt="png" /></p>

<pre><code class="language-python"># Add augmentation and mask resizing.
image, image_meta, class_ids, bbox, mask = modellib.load_image_gt(
    dataset, config, image_id, augment=True, use_mini_mask=True)
log(&quot;mask&quot;, mask)
display_images([image]+[mask[:,:,i] for i in range(min(mask.shape[-1], 7))])
</code></pre>

<pre><code>mask                     shape: (56, 56, 1)           min:    0.00000  max:    1.00000
</code></pre>

<p><img src="output_15_1.png" alt="png" /></p>

<pre><code class="language-python">mask = utils.expand_mask(bbox, mask, image.shape)
visualize.display_instances(image, bbox, mask, class_ids, dataset.class_names)
</code></pre>

<p><img src="output_16_0.png" alt="png" /></p>

<h2 id="锚点">锚点</h2>

<p>锚的顺序很重要。在训练和预测阶段使用相同的顺序。它必须匹配卷积执行的顺序。</p>

<p>对于一个FPN网络来说，定位锚点的方式必须能够很容易地将锚点与预测锚点分数和移位的卷积层输出相匹配。
*先按金字塔等级排序。第一级的所有锚点，然后是第二级的所有锚点，依此类推。这使得通过级别分离锚更容易。
*在每个级别中，按功能图处理顺序排序锚点。通常，卷积层处理从左上角开始并逐行向右移动的特征图。
*对于每个特征贴图单元格，为不同比例的锚点选择任何排序顺序。这里我们匹配传递给函数的比率顺序。</p>

<p>** 锚点跨度：**
在FPN架构中，前几层的特征映射是高分辨率的。例如，如果输入图像是1024x1024，那么第一层的特征meap是256x256，这会产生大约200K的锚（256 * 256 * 3）。这些锚点是32x32像素，它们相对于图像像素的步幅是4像素，所以有很多重叠。如果我们为特征映射中的每个其他单元生成锚，我们可以显着减少负载。例如，2的步幅会将锚的数量减少4。</p>

<p>在这个实现中，我们使用2的锚定步幅，这与纸张不同。</p>

<pre><code class="language-python"># Generate Anchors
anchors = utils.generate_pyramid_anchors(config.RPN_ANCHOR_SCALES, 
                                          config.RPN_ANCHOR_RATIOS,
                                          config.BACKBONE_SHAPES,
                                          config.BACKBONE_STRIDES, 
                                          config.RPN_ANCHOR_STRIDE)

# Print summary of anchors
num_levels = len(config.BACKBONE_SHAPES)
anchors_per_cell = len(config.RPN_ANCHOR_RATIOS)
print(&quot;Count: &quot;, anchors.shape[0])
print(&quot;Scales: &quot;, config.RPN_ANCHOR_SCALES)
print(&quot;ratios: &quot;, config.RPN_ANCHOR_RATIOS)
print(&quot;Anchors per Cell: &quot;, anchors_per_cell)
print(&quot;Levels: &quot;, num_levels)
anchors_per_level = []
for l in range(num_levels):
    num_cells = config.BACKBONE_SHAPES[l][0] * config.BACKBONE_SHAPES[l][1]
    anchors_per_level.append(anchors_per_cell * num_cells // config.RPN_ANCHOR_STRIDE**2)
    print(&quot;Anchors in Level {}: {}&quot;.format(l, anchors_per_level[l]))
</code></pre>

<pre><code>Count:  65472
Scales:  (32, 64, 128, 256, 512)
ratios:  [0.5, 1, 2]
Anchors per Cell:  3
Levels:  5
Anchors in Level 0: 49152
Anchors in Level 1: 12288
Anchors in Level 2: 3072
Anchors in Level 3: 768
Anchors in Level 4: 192
</code></pre>

<p>Visualize anchors of one cell at the center of the feature map of a specific level.</p>

<pre><code class="language-python">## Visualize anchors of one cell at the center of the feature map of a specific level

# Load and draw random image
image_id = np.random.choice(dataset.image_ids, 1)[0]
image, image_meta, _, _, _ = modellib.load_image_gt(dataset, config, image_id)
fig, ax = plt.subplots(1, figsize=(10, 10))
ax.imshow(image)
levels = len(config.BACKBONE_SHAPES)

for level in range(levels):
    colors = visualize.random_colors(levels)
    # Compute the index of the anchors at the center of the image
    level_start = sum(anchors_per_level[:level]) # sum of anchors of previous levels
    level_anchors = anchors[level_start:level_start+anchors_per_level[level]]
    print(&quot;Level {}. Anchors: {:6}  Feature map Shape: {}&quot;.format(level, level_anchors.shape[0], 
                                                                config.BACKBONE_SHAPES[level]))
    center_cell = config.BACKBONE_SHAPES[level] // 2
    center_cell_index = (center_cell[0] * config.BACKBONE_SHAPES[level][1] + center_cell[1])
    level_center = center_cell_index * anchors_per_cell 
    center_anchor = anchors_per_cell * (
        (center_cell[0] * config.BACKBONE_SHAPES[level][1] / config.RPN_ANCHOR_STRIDE**2) \
        + center_cell[1] / config.RPN_ANCHOR_STRIDE)
    level_center = int(center_anchor)

    # Draw anchors. Brightness show the order in the array, dark to bright.
    for i, rect in enumerate(level_anchors[level_center:level_center+anchors_per_cell]):
        y1, x1, y2, x2 = rect
        p = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, facecolor='none',
                              edgecolor=(i+1)*np.array(colors[level]) / anchors_per_cell)
        ax.add_patch(p)

</code></pre>

<pre><code>/usr/local/lib/python3.5/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
  &quot;the returned array has changed.&quot;, UserWarning)


Level 0. Anchors:  49152  Feature map Shape: [256 256]
Level 1. Anchors:  12288  Feature map Shape: [128 128]
Level 2. Anchors:   3072  Feature map Shape: [64 64]
Level 3. Anchors:    768  Feature map Shape: [32 32]
Level 4. Anchors:    192  Feature map Shape: [16 16]
</code></pre>

<p><img src="output_20_2.png" alt="png" /></p>

<h2 id="数据生成器">数据生成器</h2>

<pre><code class="language-python"># Create data generator
random_rois = 2000
g = modellib.data_generator(
    dataset, config, shuffle=True, random_rois=random_rois, 
    batch_size=4,
    detection_targets=True)
</code></pre>

<pre><code class="language-python"># Uncomment to run the generator through a lot of images
# to catch rare errors
# for i in range(1000):
#     print(i)
#     _, _ = next(g)
</code></pre>

<pre><code class="language-python"># Get Next Image
if random_rois:
    [normalized_images, image_meta, rpn_match, rpn_bbox, gt_class_ids, gt_boxes, gt_masks, rpn_rois, rois], \
    [mrcnn_class_ids, mrcnn_bbox, mrcnn_mask] = next(g)
    
    log(&quot;rois&quot;, rois)
    log(&quot;mrcnn_class_ids&quot;, mrcnn_class_ids)
    log(&quot;mrcnn_bbox&quot;, mrcnn_bbox)
    log(&quot;mrcnn_mask&quot;, mrcnn_mask)
else:
    [normalized_images, image_meta, rpn_match, rpn_bbox, gt_boxes, gt_masks], _ = next(g)
    
log(&quot;gt_class_ids&quot;, gt_class_ids)
log(&quot;gt_boxes&quot;, gt_boxes)
log(&quot;gt_masks&quot;, gt_masks)
log(&quot;rpn_match&quot;, rpn_match, )
log(&quot;rpn_bbox&quot;, rpn_bbox)
image_id = image_meta[0][0]
print(&quot;image_id: &quot;, image_id, dataset.image_reference(image_id))

# Remove the last dim in mrcnn_class_ids. It's only added
# to satisfy Keras restriction on target shape.
mrcnn_class_ids = mrcnn_class_ids[:,:,0]
</code></pre>

<pre><code>/usr/local/lib/python3.5/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
  &quot;the returned array has changed.&quot;, UserWarning)


rois                     shape: (4, 128, 4)           min:    0.00000  max: 1023.00000
mrcnn_class_ids          shape: (4, 128, 1)           min:    0.00000  max:   67.00000
mrcnn_bbox               shape: (4, 128, 81, 5)       min:   -3.58824  max:    3.45455
mrcnn_mask               shape: (4, 128, 28, 28, 81)  min:    0.00000  max:    1.00000
gt_boxes                 shape: (4, 100, 5)           min:    0.00000  max: 1024.00000
gt_masks                 shape: (4, 56, 56, 100)      min:    0.00000  max:    1.00000
rpn_match                shape: (4, 65472, 1)         min:   -1.00000  max:    1.00000
rpn_bbox                 shape: (4, 256, 4)           min:   -4.60969  max:    1.76777
image_id:  2937 http://cocodataset.org/#explore?id=135453
</code></pre>

<pre><code class="language-python">b = 0

# Restore original image (reverse normalization)
sample_image = modellib.unmold_image(normalized_images[b], config)

# Compute anchor shifts.
indices = np.where(rpn_match[b] == 1)[0]
refined_anchors = utils.apply_box_deltas(anchors[indices], rpn_bbox[b, :len(indices)] * config.RPN_BBOX_STD_DEV)
log(&quot;anchors&quot;, anchors)
log(&quot;refined_anchors&quot;, refined_anchors)

# Get list of positive anchors
positive_anchor_ids = np.where(rpn_match[b] == 1)[0]
print(&quot;Positive anchors: {}&quot;.format(len(positive_anchor_ids)))
negative_anchor_ids = np.where(rpn_match[b] == -1)[0]
print(&quot;Negative anchors: {}&quot;.format(len(negative_anchor_ids)))
neutral_anchor_ids = np.where(rpn_match[b] == 0)[0]
print(&quot;Neutral anchors: {}&quot;.format(len(neutral_anchor_ids)))

# ROI breakdown by class
for c, n in zip(dataset.class_names, np.bincount(mrcnn_class_ids[b].flatten())):
    if n:
        print(&quot;{:23}: {}&quot;.format(c[:20], n))

# Show positive anchors
visualize.draw_boxes(sample_image, boxes=anchors[positive_anchor_ids], 
                     refined_boxes=refined_anchors)
</code></pre>

<pre><code>anchors                  shape: (65472, 4)            min: -362.03867  max: 1258.03867
refined_anchors          shape: (4, 4)                min:  112.99997  max:  912.00000
Positive anchors: 4
Negative anchors: 252
Neutral anchors: 65216
BG                     : 90
chair                  : 6
bed                    : 30
remote                 : 2
</code></pre>

<p><img src="output_25_1.png" alt="png" /></p>

<pre><code class="language-python"># Show negative anchors
visualize.draw_boxes(sample_image, boxes=anchors[negative_anchor_ids])
</code></pre>

<p><img src="output_26_0.png" alt="png" /></p>

<pre><code class="language-python"># Show neutral anchors. They don't contribute to training.
visualize.draw_boxes(sample_image, boxes=anchors[np.random.choice(neutral_anchor_ids, 100)])
</code></pre>

<p><img src="output_27_0.png" alt="png" /></p>

<h2 id="rois">ROIs</h2>

<pre><code class="language-python">if random_rois:
    # Class aware bboxes
    bbox_specific = mrcnn_bbox[b, np.arange(mrcnn_bbox.shape[1]), mrcnn_class_ids[b], :]

    # Refined ROIs
    refined_rois = utils.apply_box_deltas(rois[b].astype(np.float32), bbox_specific[:,:4] * config.BBOX_STD_DEV)

    # Class aware masks
    mask_specific = mrcnn_mask[b, np.arange(mrcnn_mask.shape[1]), :, :, mrcnn_class_ids[b]]

    visualize.draw_rois(sample_image, rois[b], refined_rois, mask_specific, mrcnn_class_ids[b], dataset.class_names)
    
    # Any repeated ROIs?
    rows = np.ascontiguousarray(rois[b]).view(np.dtype((np.void, rois.dtype.itemsize * rois.shape[-1])))
    _, idx = np.unique(rows, return_index=True)
    print(&quot;Unique ROIs: {} out of {}&quot;.format(len(idx), rois.shape[1]))
</code></pre>

<pre><code>Positive ROIs:  38
Negative ROIs:  90
Positive Ratio: 0.30
Unique ROIs: 128 out of 128
</code></pre>

<p><img src="output_29_1.png" alt="png" /></p>

<pre><code class="language-python">if random_rois:
    # Dispalay ROIs and corresponding masks and bounding boxes
    ids = random.sample(range(rois.shape[1]), 8)

    images = []
    titles = []
    for i in ids:
        image = visualize.draw_box(sample_image.copy(), rois[b,i,:4].astype(np.int32), [255, 0, 0])
        image = visualize.draw_box(image, refined_rois[i].astype(np.int64), [0, 255, 0])
        images.append(image)
        titles.append(&quot;ROI {}&quot;.format(i))
        images.append(mask_specific[i] * 255)
        titles.append(dataset.class_names[mrcnn_class_ids[b,i]][:20])

    display_images(images, titles, cols=4, cmap=&quot;Blues&quot;, interpolation=&quot;none&quot;)
</code></pre>

<p><img src="output_30_0.png" alt="png" /></p>

<pre><code class="language-python"># Check ratio of positive ROIs in a set of images.
if random_rois:
    limit = 10
    temp_g = modellib.data_generator(
        dataset, config, shuffle=True, random_rois=10000, 
        batch_size=1, detection_targets=True)
    total = 0
    for i in range(limit):
        _, [ids, _, _] = next(temp_g)
        positive_rois = np.sum(ids[0] &gt; 0)
        total += positive_rois
        print(&quot;{:5} {:5.2f}&quot;.format(positive_rois, positive_rois/ids.shape[1]))
    print(&quot;Average percent: {:.2f}&quot;.format(total/(limit*ids.shape[1])))
</code></pre>

<pre><code>   42  0.33
   42  0.33


/usr/local/lib/python3.5/dist-packages/scipy/ndimage/interpolation.py:600: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.
  &quot;the returned array has changed.&quot;, UserWarning)


   42  0.33
   42  0.33
   42  0.33
   42  0.33
   42  0.33
   42  0.33
   42  0.33
   42  0.33
Average percent: 0.33
</code></pre>

    </div>

    


    
    

    

    


  </div>
</article>

<footer class="site-footer">
  <div class="container">

    

    <p class="powered-by">

      &copy; 2017 Yida Wang &middot; 

      Powered by the
      <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
      <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <button type="button" class="close btn-large" data-dismiss="modal">&times;</button>
        <h4 class="modal-title">Cite</h4>
      </div>
      <div>
        <pre><code class="modal-body tex"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-primary btn-outline js-copy-cite" href="#" target="_blank">
          <i class="fa fa-copy"></i> Copy
        </a>
        <a class="btn btn-primary btn-outline js-download-cite" href="#" target="_blank">
          <i class="fa fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    

    

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js" integrity="sha512-3P8rXCuGJdNZOnUx/03c1jOTnMn3rP63nBip5gOP2qmUh5YAdVAvFZ1E+QLZZbC1rtMrQb+mah3AfYW11RUrWA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>
    
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
      

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous"></script>
    
    

  </body>
</html>

